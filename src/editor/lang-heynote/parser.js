// This file was generated by lezer-generator. You probably shouldn't edit it.
import {LRParser} from "@lezer/lr"
import {noteContent} from "./external-tokens.js"
export const parser = LRParser.deserialize({
  version: 14,
  states: "!jQQOPOOOVOPO'#C`O[OQO'#C_OOOO'#Cc'#CcQQOPOOOaOPO,58zOOOO,58y,58yOOOO-E6a-E6aOfOPO1G.fOOOQ7+$Q7+$QOnOPO7+$QOOOQ<<Gl<<Gl",
  stateData: "s~OXPO~OYTO~OPUO~OTWO~OUYOXXO~OXZO~O",
  goto: "gWPPPX]PPaTROSTQOSQSORVS",
  nodeNames: "âš  NoteContent Document Note NoteDelimiter NoteLanguage Auto",
  maxTerm: 10,
  skippedNodes: [0],
  repeatNodeCount: 1,
  tokenData: "+n~R`YZ!T}!O!Y#V#W!e#X#Y$R#Z#[$q#[#]$w#^#_%Z#`#a&w#a#b'a#d#e(`#f#g({#g#h)b#h#i*W#l#m$}#m#n+V%&x%&y+]~!YOX~~!]P#T#U!`~!eOU~~!hR#`#a!q#d#e#f#g#h#l~!tP#c#d!w~!zP#^#_!}~#QP#i#j#T~#WP#f#g#Z~#^P#X#Y#a~#fOT~~#iP#d#e#a~#oQ#[#]#u#g#h#a~#xP#T#U#{~$OP#f#g#f~$UP#f#g$X~$[P#`#a$_~$bP#T#U$e~$hP#b#c$k~$nP#Z#[#a~$tP#c#d$X~$zP#h#i$}~%QP#a#b%T~%WP#`#a#a~%^Q#T#U%d#g#h&h~%gP#j#k%j~%mP#T#U%p~%uPT~#g#h%x~%{P#V#W&O~&RP#f#g&U~&XP#]#^&[~&_P#d#e&b~&eP#h#i#a~&kQ#c#d&q#l#m#a~&tP#b#c#a~&zP#X#Y&}~'QP#n#o'T~'WP#X#Y'Z~'^P#f#g#a~'dP#T#U'g~'jQ#f#g'p#h#i(Y~'sP#_#`'v~'yP#W#X'|~(PP#c#d(S~(VP#k#l&q~(]P#[#]#a~(cQ#[#]#f#m#n(i~(lP#h#i(o~(rP#[#](u~(xP#c#d&q~)OP#i#j)R~)UQ#U#V)[#g#h&b~)_P#m#n#a~)eR#[#])n#e#f%T#k#l)z~)qP#X#Y)t~)wP#`#a%T~)}P#]#^*Q~*TP#Y#Z&b~*ZS#X#Y*g#c#d$}#g#h*m#m#n*s~*jP#l#m&b~*pP#l#m#a~*vP#d#e*y~*|P#X#Y+P~+SP#g#h%x~+YP#T#U$}~+`P%&x%&y+c~+fP%&x%&y+i~+nOY~",
  tokenizers: [0, noteContent],
  topRules: {"Document":[0,2]},
  tokenPrec: 0
})
